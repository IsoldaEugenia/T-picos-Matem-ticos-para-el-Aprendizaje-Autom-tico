{"cells":[{"cell_type":"markdown","metadata":{"id":"qxWvhYY1wEIp"},"source":["# Unidad 1 - 04 Trabajo Práctico: Flujo de trabajo en ML"]},{"cell_type":"markdown","metadata":{"id":"C2mBdd4t2edy"},"source":["El primer TP consistirá en seguir la notebook, no habrá mucho para resolver pero sí para aprender."]},{"cell_type":"markdown","metadata":{"id":"rLGUwSKY2edy"},"source":["## 1. Herramientas de trabajo\n","\n","### 1. 1 Scikit-learn\n","\n","En este TP implementaremos la herramienta scikit-learn, a la cual accederemos a través de Python. Esta herramienta permite hacer muchos cálculos con una simple función. La estructura de scikit-learn está, al igual que el lenguaje Python, orientada a objetos (https://es.wikipedia.org/wiki/Programación_orientada_a_objetos).\n","\n","Scikit-learn es muy popular pues tiene ya incorporadas funciones muy útiles y sólo hay que importarlas. No se precisa escribir códio para definir conceptos matemáticos o estadísticos, ya está hecho por nosotrxs y está testeado y documentado exhaustivamente (https://www.researchgate.net/publication/51969319_Scikit-learn_Machine_Learning_in_Python).\n","\n","\n","### 1.2 Datasets\n","\n","Usaremos los siguientes datasets:\n","\n","- California housing dataset\n","\n","MÁS INFO EN https://www.kaggle.com/datasets/camnugent/california-housing-prices\n","\n","- Ames housing dataset\n","\n","MÁS INFO EN https://www.kaggle.com/datasets/marcopale/housing\n","\n","- Boston housing dataset\n","\n","NO lo usaremos por razones éticas que, entre otra bibliografía, pueden leerse en la descripción cuando corre el siguiente código:\n","\n","from sklearn.datasets import load_boston\n","\n","boston  = load_boston()\n"]},{"cell_type":"markdown","metadata":{"id":"FfQSjncC2edz"},"source":["## 2. Flujo de trabajo"]},{"cell_type":"markdown","metadata":{"id":"TpMBGyLP2edz"},"source":["Habrá que ir siguiendo los pasos, para ir incorporando el flujo de trabajo."]},{"cell_type":"markdown","metadata":{"id":"vkvSdzPG2ed0"},"source":["### 2.1 PASO 1: obener los datos\n","\n","Cabe aclarar que los datos que se obtienen de fuentes del mundo real no están \"limpios\", en el sentido de que no están preparados para el análisis. Por suerte, los datos que ya vienen incluidos en paquetes como el de scikit-learn, ya están preparados para su uso inmediato.\n","\n","Este paso es, en general, muy tedioso, lleva mucho esfuerzo y muchas horas. Se calcula que lleva, desde la obtención de los datos hasta la limpieza de los mismos, el 80% del tiempo en el flujo de trabajo. Como no es la parte que nos interese, este paso para nostrxs será muy simple."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"5OPqgDiZ2ed0","executionInfo":{"status":"ok","timestamp":1693572847188,"user_tz":180,"elapsed":3376,"user":{"displayName":"isolda cardoso","userId":"01318377289461398532"}}},"outputs":[],"source":["from sklearn.datasets import fetch_california_housing\n","housing = fetch_california_housing()"]},{"cell_type":"markdown","metadata":{"id":"Beiv8tMx2ed1"},"source":["### 2.2 PASO 2: crear las variables características (features) y objetivo (target)"]},{"cell_type":"markdown","metadata":{"id":"qj8ufdrx2ed1"},"source":["En este paso guardaremos las características (features) y objetivos (target) en distintas variables para que el código sea más comprensible y luego podamos pasar rápidamente a las funciones que las utilizan separadamente.\n","\n","Para esto usaremos el paquete de pandas para Python, que guarda datos de filas y columnas en un objeto llamado DataFrame.\n","\n","Cuando trabajamos con datos guardados en un DataFrame (algo parecido a una matriz), es útil nombrar las columnas."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"KKvT6hhr2ed1","executionInfo":{"status":"ok","timestamp":1693572850434,"user_tz":180,"elapsed":1104,"user":{"displayName":"isolda cardoso","userId":"01318377289461398532"}}},"outputs":[],"source":["import pandas as pd\n","features = pd.DataFrame(\n","    data = housing.data,\n","    columns = housing.feature_names)\n","target = housing.target"]},{"cell_type":"markdown","metadata":{"id":"Dkfl2YlZ2ed2"},"source":["### 2.3 PASO 3: descomponer el dataset en entrenamiento y testeo"]},{"cell_type":"markdown","metadata":{"id":"2GFpPPAT2ed2"},"source":["Separamos el dataset en dos partes: entrenamiento y testeo. Scikit-learn tiene una función que lo hace, pues es un procedimiento bastante común. Esta función se llama train_test_split.\n","\n","Hemos elegido para este caso usar 80% de los datos para entrenar (¿dónde aparece esta elección en el código?).\n","\n","La función train_test_split devuelve una cuaterna ordenada consistente de: características de entrenamiento (training features), características de testeo (test features), objetivos de entrenamiento (training targets) y objetivos de testeo (test targets).\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"F2sozuo72ed2","executionInfo":{"status":"ok","timestamp":1693572857240,"user_tz":180,"elapsed":318,"user":{"displayName":"isolda cardoso","userId":"01318377289461398532"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","(X_training, X_test, y_training, y_test ) = train_test_split(features, target, train_size = 0.8)"]},{"cell_type":"markdown","metadata":{"id":"8Jf85WKZ2ed2"},"source":["### 2.4 PASO 4: crear y entrenar un modelo a partir del dataset de entrenamiento"]},{"cell_type":"markdown","metadata":{"id":"ZlXP7PF_2ed2"},"source":["A partir de los datos, creamos y entrenamos nuestro modelo.\n","\n","Esta parte es iterativa, en este caso la haremos simple y automatizada.\n","\n","Para ir aprendiendo un poco más sobre scikit-learn, veremos lo siguiente: scikit-learn se basa en la noción de Pipeline, que no tiene una traducción adecuada (literalmente significa \"tubería\"), pero que se utiliza en la arquitectura de programas para referirse al recurso de tareas conectadas secuencialmente (o en paralelo) para el procesamiento de los datos. Es decir, son cadenas de funciones compuestas a través de las cales pasan datos de una a la siguiente.\n","\n","En nuestro caso, la pipeline tendrá sólo dos pasos, pero tengamos en cuenta que pueden tener muchos.\n","\n","La primera función en el pipeline es SelectKBest, con k=5. Esta función elige las 5 características (features) del training dataset que son más útiles para predecir el target, y por defecto usa la F-estadística usada en análisis de varianza (aunque se pueden especificar otras medidas).\n","\n","La segunda función en el pipeline toma esas 5 features crea un modelo lineal.\n","\n","Una pipeline que culmina entrenando (fitting) un modelo se llama un estimador (estimator) en la jerga de scikit-learn, en contraste con una pipeline que meramente modifica los datos, y se llama transformador (transformer).\n","\n","El siguiente código entrena elmodelo sólo con los datos de entrenamiento y guarda el resultado en una variable llamada fit_model.\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"tO1xqHtc2ed2","executionInfo":{"status":"ok","timestamp":1693572865004,"user_tz":180,"elapsed":1268,"user":{"displayName":"isolda cardoso","userId":"01318377289461398532"}}},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.linear_model import LinearRegression\n","estimator = Pipeline([('select', SelectKBest(k=5)),('model',LinearRegression())])\n","fit_model = estimator.fit(X=X_training, y=y_training)"]},{"cell_type":"markdown","metadata":{"id":"yweiA2Co2ed2"},"source":["### 2.5 PASO 5: evaluar el modelo"]},{"cell_type":"markdown","metadata":{"id":"YCYoWEIs2ed2"},"source":["En este paso evaluamos el modelo aplicándolo al dataset de testeo.\n","\n","En este caso el concepto estadístico usado es MSE (error medio al cuadrado, \"mean squared error\") y ya está definido en scikit-learn. Y como queremos su raíz, elevamos a la 1/2."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i3bV5Fxo2ed3","executionInfo":{"status":"ok","timestamp":1693572870693,"user_tz":180,"elapsed":313,"user":{"displayName":"isolda cardoso","userId":"01318377289461398532"}},"outputId":"04354294-7d14-44ec-b154-b3910ecd121d"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.7427563699204726\n"]}],"source":["predictions = fit_model.predict(X=X_test)\n","from sklearn.metrics import mean_squared_error\n","print(mean_squared_error(y_test, predictions)**0.5)"]},{"cell_type":"markdown","metadata":{"id":"iGLzaBz22ed3"},"source":["### 3. EJERCITACIÓN"]},{"cell_type":"markdown","metadata":{"id":"PeAAHAPy2ed3"},"source":["A continuación proponemos ejercicios para familiarizarnos con buscar, seleccionar, implementar, etc. Tenemos todo a nuestro alcance, hay que aprender a elegir qué buscar, dónde buscarlo, cómo usarlo, etc."]},{"cell_type":"markdown","metadata":{"id":"etpImjP-2ed3"},"source":["1) Interpretar las salidas \"prediction\" y el valor que da el error.\n","\n","2) Realizar el flujo de trabajo para el AMES housing dataset. Observar que hay que buscar en la documentación para cargarlo desde scikit-learn.\n","\n","3) Dado que en el pipeline sólo hicimos dos pasos, extenderlo a un modelo más complejo agregando pasos. Para esto puede agregarse, por ejemplo, un paso que utilice SVM para transformar una o más variables. Investigar cuál podría ser otra función posible para agregar al pipeline, e implementarlo."]},{"cell_type":"markdown","metadata":{"id":"gyp-4Ql-2ed3"},"source":["\n","---\n","\n","\n","Estas notebooks corresponden a la asignatura electiva para la Licenciatura en Matemática del Departamento de Matemática de la Escuela de Cs. Exactas y Naturales, de la Facultad de Cs. Exactas, Ingenieria y Agrimensura (FCEIA) de la Universidad Nacional de Rosario, Argentina. Año 2023.\n","\n","Fueron confeccionadas a tal fin por las docentes investigadoras de la FCEIA Isolda Cardoso y Jorgelina Walpen. Este trabajo de análisis, estudio, recopilación, traducción, armado, pruebas y errores, nos ha llevado mucho tiempo. Cuando hay tanta información disponible es complicado extraer lo que, al menos para nosotras, es relevante. Hay muchísimos otros recursos y tutoriales, nosotras armamos este.\n","\n","Si estas notebooks son reproducidas, solicitamos citar la fuente.\n","\n","Dejamos nuestras páginas laborales y repositorios de GitHub. Seguramente en un futuro las pondremos a disposición en el Repositorio Hipermedial de la UNR.\n","\n","Isolda: Te dejo mi página laboral https://www.fceia.unr.edu.ar/~isolda/ y mi GitHub https://github.com/IsoldaEugenia. Sentite libre de contactarme.\n","\n","Jorgelina: https://www.fceia.unr.edu.ar/~walpen/ y  https://github.com/JorWalpen"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BKVuRlRt2ed3"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}